{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/love/miniconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, get_response_synthesizer,ServiceContext\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "import chromadb\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.core.indices.struct_store import NLSQLTableQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize client, setting path to save data\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the embeddings model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "\n",
    "# Initialize the language model\n",
    "Settings.llm = Ollama(model=\"llama3.1\", request_timeout=360.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some documents\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "# Create the index with the embeddings and language model\n",
    "index = VectorStoreIndex.from_documents(documents,storage_context=storage_context)#768\n",
    "\n",
    "# Create the query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VectorStoreIndex and query engine with a similarity threshold of 20\n",
    "index_db = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "query_engine = index_db.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index_db,\n",
    "    similarity_top_k=3,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"refine\")\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders. \n",
      "\n",
      "When the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Jessica Livingston\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample Tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample Tool\n",
    "def sum(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools([multiply_tool], llm=Settings.llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\"4 time 7\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "CACHE_EXPIRATION = 300  # Cache expiration time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_store(query: str) -> list:\n",
    "    \"\"\"Query the vector store and cache the results.\"\"\"\n",
    "    cache_key = f\"vector_store:{query}\"\n",
    "    cached_result = cache_get(cache_key)\n",
    "    if cached_result:\n",
    "        print(\"Cache hit for vector store\")\n",
    "        return cached_result\n",
    "    \n",
    "    print(f\"Querying vector store for: {query}\")\n",
    "    # Replace with actual vector store query logic\n",
    "    result = [\"result1\", \"result2\"]\n",
    "    \n",
    "    # Store the result in the cache\n",
    "    cache_set(cache_key, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VectorStoreIndex and query engine\n",
    "index_db = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "query_engine = index_db.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL-based query engine for the student table with caching\n",
    "def query_student_table(query: str) -> dict:\n",
    "    \"\"\"Query the student SQL table and cache the results.\"\"\"\n",
    "    cache_key = f\"student_table:{query}\"\n",
    "    cached_result = cache_get(cache_key)\n",
    "    if cached_result:\n",
    "        print(\"Cache hit for student table\")\n",
    "        return cached_result\n",
    "    \n",
    "    # Placeholder for actual SQL query logic\n",
    "    print(f\"Querying SQL database for: {query}\")\n",
    "    result = {\"total_students\": 100}  # Replace with actual query results\n",
    "    \n",
    "    # Store the result in the cache\n",
    "    cache_set(cache_key, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select\n",
    ")\n",
    "\n",
    "# Update the connection string with your PostgreSQL credentials\n",
    "engine = create_engine(\"postgresql://davide:jw8s0F4@localhost:5432/llm\")\n",
    "\n",
    "sql_database = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "student_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"students\"],\n",
    "    llm=Settings.llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_tool = QueryEngineTool(\n",
    "    student_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"student_search\",\n",
    "        description=\"Tool to query data related to students and their marks.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "RAG_tool = QueryEngineTool(\n",
    "    query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"RAG_search\",\n",
    "        description=\"Tool to answer using documents\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "query_engine_tools = [student_tool,multiply_tool,RAG_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(query_engine_tools, llm=Settings.llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e1fb79f4-7930-440d-9bb8-ec225d872946. Step input: who is jessica\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: RAG_search\n",
      "Action Input: {'input': 'jessica'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: She was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders. \n",
      "\n",
      "When the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm. It took them weeks to make up their minds, and during this time I started telling her about all the things that needed to be fixed about venture capital. They should make a larger number of smaller investments instead of a handful of giant ones, they should be funding younger, more technical founders instead of MBAs, they should let the founders remain as CEO, and so on. \n",
      "\n",
      "\u001b[0m> Running step 79a626d8-0f19-453d-b602-c296eb60f463. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is still English. I need to process the additional information you provided.\n",
      "Action: RAG_search\n",
      "Action Input: {'input': 'marketing job at a Boston VC firm'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: It sounds like a challenging but rewarding opportunity to be part of a company that's helping startups grow.  There might be a lot of learning involved, especially if you're new to the venture capital world. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m> Running step 1eb9947e-6f19-4b64-b802-4002f511950c. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is still English. I need to use a tool to help me answer the question.\n",
      "Action: student_search\n",
      "Action Input: {'input': 'venture capital world'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: It seems there's been a misunderstanding here!\n",
      "\n",
      "Since the input query \"venture capital world\" isn't a specific SQL question, but rather a generic topic, and you've pointed out that the response is trying to interpret it as an SQL query (which wouldn't make sense for this kind of query), I'll take a step back.\n",
      "\n",
      "To provide a synthesized response in a human-friendly format, here's how I would approach this:\n",
      "\n",
      "**Synthesized Response:**\n",
      "\n",
      "\"Venture capital refers to funding provided by investors to startups and small businesses with high growth potential. This type of funding is typically provided by venture capitalists (VCs) who invest money in exchange for equity in the company.\n",
      "\n",
      "In the context of the world, venture capital plays a crucial role in promoting innovation, job creation, and economic growth. It allows companies to scale quickly, take risks on new ideas, and disrupt traditional industries.\n",
      "\n",
      "However, it's worth noting that the venture capital industry is complex and has its own set of rules, challenges, and best practices. If you're interested in learning more about venture capital, I'd be happy to provide further information or point you in the direction of reliable resources.\"\n",
      "\n",
      "This response is an attempt to interpret the input query in a human-friendly format, providing some context and basic information on the topic of venture capital.\n",
      "\u001b[0m> Running step 68f1aeb4-ba8a-45a2-b711-bc985da0f491. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Venture capital refers to funding provided by investors to startups and small businesses with high growth potential. This type of funding is typically provided by venture capitalists (VCs) who invest money in exchange for equity in the company.\n",
      "\n",
      "In the context of the world, venture capital plays a crucial role in promoting innovation, job creation, and economic growth. It allows companies to scale quickly, take risks on new ideas, and disrupt traditional industries.\n",
      "\n",
      "However, it's worth noting that the venture capital industry is complex and has its own set of rules, challenges, and best practices. If you're interested in learning more about venture capital, I'd be happy to provide further information or point you in the direction of reliable resources.\n",
      "\u001b[0mVenture capital refers to funding provided by investors to startups and small businesses with high growth potential. This type of funding is typically provided by venture capitalists (VCs) who invest money in exchange for equity in the company.\n",
      "\n",
      "In the context of the world, venture capital plays a crucial role in promoting innovation, job creation, and economic growth. It allows companies to scale quickly, take risks on new ideas, and disrupt traditional industries.\n",
      "\n",
      "However, it's worth noting that the venture capital industry is complex and has its own set of rules, challenges, and best practices. If you're interested in learning more about venture capital, I'd be happy to provide further information or point you in the direction of reliable resources.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"who is jessica\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 773254d6-fd70-4084-ad68-9c258f2cd42b. Step input: Provide a concise and direct answer to the following question: Who is Jessica?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: student_search\n",
      "Action Input: {'input': 'Jessica'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: It looks like you're trying to use me as a database interface, but I'm not designed for that.\n",
      "\n",
      "However, since the input \"Jessica\" isn't a valid SQL query either, let's try something else. If you meant to ask about someone named Jessica, I can try to provide some information on a fictional or well-known person with that name.\n",
      "\n",
      "Would you like me to tell you something about Jessica Alba, Jessica Simpson, or perhaps a character from literature or mythology?\n",
      "\u001b[0m> Running step 45c692d5-61aa-4402-b97b-05de6d669db6. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: You are correct that the student_search tool is not suitable for this task. I need to try a different approach.\n",
      "Action: RAG_search\n",
      "Action Input: {'input': 'Jessica'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Jessica was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders. \n",
      "\n",
      "When the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm. It took them weeks to make up their minds, and during this time I started telling her about all the things that needed to be fixed about venture capital. They should make a larger number of smaller investments instead of a handful of giant ones, they should be funding younger, more technical founders instead of MBAs, they should let the founders remain as CEO, and so on. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m> Running step 3b4839ec-340c-4130-88ac-7b4445dea40f. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I think I'm starting to get a better understanding of who Jessica is. It sounds like she's a marketing professional with experience in the startup world.\n",
      "Action: RAG_search\n",
      "Action Input: {'input': 'Jessica', 'context': 'marketing, startups, Boston investment bank, VC firm'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Jessica was in charge of marketing at a Boston investment bank.  This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders.\n",
      "\n",
      "When the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm.  As Jessica and I were walking home from dinner on March 11, at the corner of Garden and Walker streets, these three threads converged. Screw the VCs who were taking so long to make up their minds. We'd start our own investment firm and actually implement the ideas we'd been talking about.   \n",
      "\n",
      "\u001b[0m> Running step 3e1434e9-86b1-4e68-83b8-fbc9c1090832. Step input: None\n",
      "\u001b[1;3;34mObservation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
      "\u001b[0m> Running step 63ed2afc-d786-4f74-9728-74985c2414b3. Step input: None\n",
      "\u001b[1;3;34mObservation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
      "\u001b[0m> Running step a3d1e1dc-7f4c-4e49-a0d3-2027e407f976. Step input: None\n",
      "\u001b[1;3;34mObservation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
      "\u001b[0m> Running step 9519f65e-eb81-417d-a752-8577dc3ef3bd. Step input: None\n",
      "\u001b[1;3;34mObservation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Reached max iterations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnest_asyncio\u001b[39;00m\n\u001b[1;32m      3\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39machat(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide a concise and direct answer to the following question: Who is Jessica?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(response))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:255\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    252\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/callbacks/utils.py:56\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.async_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/agent/runner/base.py:671\u001b[0m, in \u001b[0;36mAgentRunner.achat\u001b[0;34m(self, message, chat_history, tool_choice)\u001b[0m\n\u001b[1;32m    666\u001b[0m     tool_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_tool_choice\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    668\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mAGENT_STEP,\n\u001b[1;32m    669\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mMESSAGES: [message]},\n\u001b[1;32m    670\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 671\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_achat(\n\u001b[1;32m    672\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m    673\u001b[0m         chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n\u001b[1;32m    674\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    675\u001b[0m         mode\u001b[38;5;241m=\u001b[39mChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[1;32m    678\u001b[0m     e\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: chat_response})\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:255\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    252\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/agent/runner/base.py:613\u001b[0m, in \u001b[0;36mAgentRunner._achat\u001b[0;34m(self, message, chat_history, tool_choice, mode)\u001b[0m\n\u001b[1;32m    610\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(AgentChatWithStepStartEvent(user_msg\u001b[38;5;241m=\u001b[39mmessage))\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;66;03m# pass step queue in as argument, assume step executor is stateless\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arun_step(\n\u001b[1;32m    614\u001b[0m         task\u001b[38;5;241m.\u001b[39mtask_id, mode\u001b[38;5;241m=\u001b[39mmode, tool_choice\u001b[38;5;241m=\u001b[39mtool_choice\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cur_step_output\u001b[38;5;241m.\u001b[39mis_last:\n\u001b[1;32m    618\u001b[0m         result_output \u001b[38;5;241m=\u001b[39m cur_step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:255\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    252\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/agent/runner/base.py:453\u001b[0m, in \u001b[0;36mAgentRunner._arun_step\u001b[0;34m(self, task_id, step, input, mode, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# TODO: figure out if you can dynamically swap in different step executors\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# not clear when you would do that by theoretically possible\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT:\n\u001b[0;32m--> 453\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_worker\u001b[38;5;241m.\u001b[39marun_step(step, task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mSTREAM:\n\u001b[1;32m    455\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_worker\u001b[38;5;241m.\u001b[39mastream_step(step, task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:255\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    252\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/callbacks/utils.py:56\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.async_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/agent/react/step.py:788\u001b[0m, in \u001b[0;36mReActAgentWorker.arun_step\u001b[0;34m(self, step, task, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marun_step\u001b[39m(\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28mself\u001b[39m, step: TaskStep, task: Task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    786\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskStepOutput:\n\u001b[1;32m    787\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run step (async).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arun_step(step, task)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/agent/react/step.py:612\u001b[0m, in \u001b[0;36mReActAgentWorker._arun_step\u001b[0;34m(self, step, task)\u001b[0m\n\u001b[1;32m    608\u001b[0m reasoning_steps, is_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aprocess_actions(\n\u001b[1;32m    609\u001b[0m     task, tools, output\u001b[38;5;241m=\u001b[39mchat_response\n\u001b[1;32m    610\u001b[0m )\n\u001b[1;32m    611\u001b[0m task\u001b[38;5;241m.\u001b[39mextra_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_reasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(reasoning_steps)\n\u001b[0;32m--> 612\u001b[0m agent_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcurrent_reasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msources\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_done:\n\u001b[1;32m    616\u001b[0m     task\u001b[38;5;241m.\u001b[39mextra_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_memory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m    617\u001b[0m         ChatMessage(content\u001b[38;5;241m=\u001b[39magent_response\u001b[38;5;241m.\u001b[39mresponse, role\u001b[38;5;241m=\u001b[39mMessageRole\u001b[38;5;241m.\u001b[39mASSISTANT)\n\u001b[1;32m    618\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/llama_index/core/agent/react/step.py:434\u001b[0m, in \u001b[0;36mReActAgentWorker._get_response\u001b[0;34m(self, current_reasoning, sources)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo reasoning steps were taken.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(current_reasoning) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iterations:\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReached max iterations.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(current_reasoning[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], ResponseReasoningStep):\n\u001b[1;32m    437\u001b[0m     response_step \u001b[38;5;241m=\u001b[39m cast(ResponseReasoningStep, current_reasoning[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: Reached max iterations."
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "response = await agent.achat(\n",
    "    \"Provide a concise and direct answer to the following question: Who is Jessica?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\"how many students got score more than 80\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\"delete record for studen8\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
